# Scripts - SOS Mulheres

Scripts Python para manuten√ß√£o e evolu√ß√£o da IA.

## ü§ñ Fine-tuning do BERT

O script `fine-tune-bert.py` permite retreinar o modelo BERT de an√°lise de sentimento baseado no feedback real das usu√°rias.

### Pr√©-requisitos

```bash
# Instalar depend√™ncias Python
pip install -r requirements.txt
```

### Vari√°veis de Ambiente

Defina as seguintes vari√°veis:

```bash
# Supabase (obrigat√≥rio)
export SUPABASE_URL="https://xxx.supabase.co"
export SUPABASE_SERVICE_ROLE_KEY="eyJxxx..."  # Service role key (admin)

# Hugging Face (opcional, apenas se quiser fazer upload)
export HUGGINGFACE_API_KEY="hf_xxx..."
```

### Uso

#### 1. Exportar dados de treinamento

Exporta feedbacks positivos (rating >= 4) dos √∫ltimos 90 dias:

```bash
python scripts/fine-tune-bert.py --export-only
```

Exportar dos √∫ltimos 30 dias:

```bash
python scripts/fine-tune-bert.py --export-only --days 30
```

Os dados ser√£o salvos em `data/training/training_data_YYYYMMDD_HHMMSS.csv`

#### 2. Treinar modelo localmente

Treina o modelo usando os dados exportados:

```bash
python scripts/fine-tune-bert.py --train
```

Com epochs personalizados:

```bash
python scripts/fine-tune-bert.py --train --epochs 5
```

O modelo treinado ser√° salvo em `models/bert-sentiment-finetuned/`

#### 3. Treinar e fazer upload para Hugging Face

```bash
python scripts/fine-tune-bert.py --upload
```

Isso ir√°:
1. Exportar dados
2. Treinar modelo
3. Fazer upload para `sosmulheres/bert-sentiment-ptbr` no Hugging Face Hub

### Pipeline Completo

Para rodar o pipeline completo (exportar ‚Üí treinar ‚Üí upload):

```bash
python scripts/fine-tune-bert.py --upload --days 90 --epochs 3
```

### Requisitos de Dados

**M√≠nimo recomendado**: 100 exemplos por emo√ß√£o (700 exemplos no total)

Se voc√™ tiver menos dados, o script ir√° avisar e pedir confirma√ß√£o para continuar.

### Estrutura de Diret√≥rios

```
scripts/
‚îú‚îÄ‚îÄ fine-tune-bert.py          # Script principal
‚îú‚îÄ‚îÄ requirements.txt           # Depend√™ncias Python
‚îî‚îÄ‚îÄ README.md                  # Esta documenta√ß√£o

data/                          # Criado automaticamente
‚îî‚îÄ‚îÄ training/
    ‚îî‚îÄ‚îÄ training_data_*.csv    # Dados exportados

models/                        # Criado automaticamente
‚îî‚îÄ‚îÄ bert-sentiment-finetuned/
    ‚îú‚îÄ‚îÄ pytorch_model.bin      # Modelo treinado
    ‚îú‚îÄ‚îÄ config.json            # Configura√ß√£o
    ‚îú‚îÄ‚îÄ tokenizer_config.json  # Tokenizer
    ‚îî‚îÄ‚îÄ metadata.json          # Metadata do treinamento
```

### Usando o Modelo Treinado

Depois de treinar, voc√™ pode usar o modelo localmente:

```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# Carregar modelo local
tokenizer = AutoTokenizer.from_pretrained('./models/bert-sentiment-finetuned')
model = AutoModelForSequenceClassification.from_pretrained('./models/bert-sentiment-finetuned')

# Ou usar do Hugging Face Hub (se fez upload)
tokenizer = AutoTokenizer.from_pretrained('sosmulheres/bert-sentiment-ptbr')
model = AutoModelForSequenceClassification.from_pretrained('sosmulheres/bert-sentiment-ptbr')
```

Para integrar no backend, atualize `sos-api/src/lib/nlp/sentiment-analyzer.ts`:

```typescript
// Trocar o modelo base
const response = await this.client.zeroShotClassification({
  model: 'sosmulheres/bert-sentiment-ptbr',  // ‚Üê Seu modelo fine-tuned
  inputs: text,
  // ...
});
```

### Automa√ß√£o (Recomendado)

Configure um cron job para retreinar mensalmente:

```bash
# Crontab (todo dia 1 do m√™s √†s 3h da manh√£)
0 3 1 * * cd /path/to/sosmulheres && python scripts/fine-tune-bert.py --upload --days 30
```

Ou use GitHub Actions / Vercel Cron Jobs.

### Monitoramento

Ap√≥s cada treinamento, o script gera `metadata.json` com:
- Data do treinamento
- N√∫mero de exemplos
- Loss de valida√ß√£o
- Distribui√ß√£o de emo√ß√µes

Use isso para monitorar a evolu√ß√£o da IA ao longo do tempo.

### Troubleshooting

**"Nenhum feedback encontrado"**
- Certifique-se de que h√° feedbacks com rating >= 4 no banco
- Verifique se a tabela `ai_feedback` est√° populada
- Tente aumentar o per√≠odo: `--days 180`

**"Labels inv√°lidas encontradas"**
- Algum feedback tem emo√ß√£o n√£o reconhecida
- O script ir√° filtrar automaticamente

**Out of Memory durante treinamento**
- Reduza `per_device_train_batch_size` no c√≥digo (linha 175)
- Use CPU ao inv√©s de GPU: remova `fp16=True`

**Erro ao fazer upload**
- Verifique `HUGGINGFACE_API_KEY`
- Certifique-se de ter permiss√£o no reposit√≥rio

---

## üìä Outros Scripts (Futuros)

### `export-feedback-report.py`
Gera relat√≥rio PDF com an√°lise de feedbacks.

### `migrate-legacy-data.py`
Migra dados legados para novo formato.

### `test-sentiment-accuracy.py`
Testa acur√°cia do modelo em dataset de teste.
